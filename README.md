# LangChain Chatbot

## ğŸ“– Overview

**LangChainâ€‘Chatbot** is a minimal yet extensible reference implementation of a conversational AI assistant built on top of **[LangChain](https://python.langchain.com/)**.  It demonstrates how to combine:

- **LLM backâ€‘ends** (OpenAI, Anthropic, Azure, etc.)
- **Retrievalâ€‘Augmented Generation (RAG)** pipelines using vector stores (FAISS, Chroma, Pinecone, â€¦)
- **Toolâ€‘use** and **agent** patterns for dynamic function calling
- **Streamlit** UI for quick prototyping and debugging

The repository is deliberately kept lightweight so developers can fork it, adapt the prompt chain, swap out components, or integrate it into larger systems.

---

## âœ¨ Features

- âœ… **Modular architecture** â€“ LLM, retriever, memory, and UI are interchangeable.
- âœ… **RAG support** â€“ Index your own documents (PDF, TXT, Markdown) and query them in realâ€‘time.
- âœ… **Chat memory** â€“ Sessionâ€‘level memory with optional persistent vectorâ€‘store backed history.
- âœ… **Tool integration** â€“ Example tools (web search, calculator) showcase LangChain's toolâ€‘use capabilities.
- âœ… **Docker ready** â€“ Oneâ€‘click container build for reproducible environments.
- âœ… **Test suite** â€“ PyTest based unit tests for core pipelines.

---

## ğŸ› ï¸ Quick Start

### Prerequisites

- Python **3.10** or newer
- An LLM API key (e.g., `OPENAI_API_KEY`)
- Optional: Docker if you prefer containerised execution

### 1. Clone the repository

```bash
git clone https://github.com/your-org/langchain-chatbot.git
cd langchain-chatbot
```

### 2. Install dependencies

```bash
python -m venv .venv
source .venv/bin/activate   # on Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Set environment variables

Create a `.env` file at the project root (or export variables in your shell):

```dotenv
# LLM provider â€“ choose one of the supported backâ€‘ends
OPENAI_API_KEY=sk-*************
# Optional â€“ Azure OpenAI configuration
AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
AZURE_OPENAI_API_KEY=********
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o

# Vector store configuration (FAISS is default, no extra vars needed)
# For Pinecone, set:
# PINECONE_API_KEY=...
# PINECONE_ENVIRONMENT=...
```

### 4. Index your knowledge base (RAG)

Place any `.txt`, `.md`, or `.pdf` files inside the `data/` directory, then run:

```bash
python scripts/index_documents.py
```

The script creates a **FAISS** index (`vector_store/faiss_index`) that the chatbot will query at runtime.

### 5. Run the chatbot UI

```bash
streamlit run app.py
```

Open `http://localhost:8501` in your browser and start chatting!

---

## ğŸ“‚ Project Structure

```
langchain-chatbot/
â”œâ”€ app.py                 # Streamlit UI entry point
â”œâ”€ chatbot.py             # Core LangChain chain (LLM + Retriever + Memory)
â”œâ”€ config.py              # Centralised configuration loader (pydantic settings)
â”œâ”€ data/                  # Sample documents for RAG
â”œâ”€ scripts/
â”‚   â””â”€ index_documents.py# Utility to build the vector store
â”œâ”€ vector_store/          # Persisted FAISS / other vector DB files
â”œâ”€ tests/                 # PyTest suite
â”‚   â””â”€ test_chatbot.py
â”œâ”€ requirements.txt       # Python dependencies
â””â”€ README.md              # <â€‘â€‘ you are here
```

---

## ğŸ§© Extending the Bot

### Swap the LLM

Edit `config.py` or set the appropriate environment variable (`OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, etc.). The `chatbot.py` factory uses `langchain.llms` to instantiate the model based on `LLM_PROVIDER`.

### Use a different vector store

Replace the FAISS loader in `scripts/index_documents.py` with any LangChain `VectorStore` implementation (e.g., `Chroma`, `Pinecone`, `Weaviate`). Update `chatbot.py` to load the new store.

### Add custom tools

1. Create a new Python module under `tools/` implementing a LangChain `Tool` subclass.
2. Register it in `chatbot.py`'s `tool_list`.
3. The LLM will automatically discover the tool via the `AgentExecutor`.

---

## ğŸ§ª Testing

Run the test suite with:

```bash
pytest -v
```

The tests cover:
- Document indexing and retrieval correctness
- Endâ€‘toâ€‘end chat flow with mock LLM responses
- Tool execution pathways

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork** the repository and create a feature branch.
2. Write clear, concise commit messages.
3. Add or update tests for new functionality.
4. Ensure `black`, `isort`, and `flake8` pass (`make lint`).
5. Open a Pull Request with a description of the changes.

See `CONTRIBUTING.md` for detailed guidelines.

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the `LICENSE` file for details.

---

## ğŸ“š Further Reading

- LangChain Documentation: https://python.langchain.com/docs/
- Retrievalâ€‘Augmented Generation Primer: https://arxiv.org/abs/2005.11401
- Streamlit Quickstart: https://docs.streamlit.io/

---

*Happy coding!*